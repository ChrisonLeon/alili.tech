---
title: 数学篇 - 朴素贝叶斯(Naive Bayes)分类算法(笔记)
tags: [Daily, 数学]
slug: 6iwpimvelxh
keywords: 人工智能,计算机数学,计算机基础,计算机,前端学人工智能,每日功课
date: 2020-09-14 00:00:00
---

## 朴素贝叶斯(Naive Bayes)

> “用客观的新信息更新我们最初关于某个事物的信念后，我们就会得到一个新的、改进了的信念。”
>  ---- 数学家托马斯·贝叶斯(Thomas Bayes，1702～1761)

当你不能准确知悉一个事物的本质时，你可以依靠与事物特定本质相关的事件出现的多少去判断其本质属性的概率。

支持某项属性的事件发生得愈多，则该属性成立的可能性就愈大。


1774年，法国数学家皮埃尔-西蒙·拉普拉斯(Pierre-Simon Laplace，1749-1827)独立地再次发现了贝叶斯公式。


![图 16](https://incomparable9527.coding.net/p/imageBed/d/imageBed/git/raw/master/3d6c983eec1f9283cb79904d2cc4cc1c7ee9654d73874ce1daf498b94fd23358.png)  

换种写法:

![图 17](https://incomparable9527.coding.net/p/imageBed/d/imageBed/git/raw/master/a1ace7950302e8e260f8397ea6c765ad2affa502ebc48d64f8b437e03eaf57ac.png)  




## 让计算机分辨水果

我们需要将水果的特征转化为计算机所能理解的数据。最常用的方式就是提取现实世界中的对象之属性，并将这些转化为数字。

比如：形状、外皮颜色、斑马纹理、重量、握感、口感。


![图 19](https://incomparable9527.coding.net/p/imageBed/d/imageBed/git/raw/master/a99743fd96d79a2d6d343ef81f988c32f9ea4b28a8ad5c2391c2658ba60c188b.png)  


将这些形容转化成数字,把重量由连续值转化成了离散值，这是因为朴素贝叶斯处理的都是离散值

![图 20](https://incomparable9527.coding.net/p/imageBed/d/imageBed/git/raw/master/c6c05b372ef0736d10734971409f755698ca90913095af1e752a7ecee88f9e7a.png)  

扩大样本,仅仅 3 个水果还不足以构成朴素贝叶斯分类所需的训练样本


![图 21](https://incomparable9527.coding.net/p/imageBed/d/imageBed/git/raw/master/d485cea0f343ac13f4056b4ec0042563ae0866e275ab17b45ad7aecedc4f41f9.png)  


### 我们如何使用贝叶斯公式 

> 用先验概率和条件概率估计后验概率。
> 
![图 22](https://incomparable9527.coding.net/p/imageBed/d/imageBed/git/raw/master/a725fc90f77e944d101977ea08e273e05f77c4160eb3ecf861a952a8719b8ac1.png)  



假定数据对象的不同属性对其归类影响时是相互独立的。此时若数据对象 o 中同时出现属性 fi 与 fj，则对象 o 属于类别 c 的概率就是这样 

> 朴素贝叶斯算法是假设各个特征之间相互独立,才可以两边相等,这也是朴素贝叶斯分类有朴素一词的来源

![图 23](https://incomparable9527.coding.net/p/imageBed/d/imageBed/git/raw/master/890407d644aa61250ee7e983ec0fd8e161679f7ff7e29a02bab486922a42e607.png)  

用 10 个水果的数据，来建立朴素贝叶斯模型

![图 24](https://incomparable9527.coding.net/p/imageBed/d/imageBed/git/raw/master/6ec393ee25603bb065911573df41cc0ce291e26087cb78c1a2f80b64e3739eb1.png)  

#### 平滑（Smoothing）
会出现结果为 0 的情况，因此我们通常取一个比这个数据集里最小统计概率还要小的极小值，来代替“零概率”。比如，我们这里取 0.01。在填充训练数据中从来没有出现过的属性值的时候，我们就会使用这种技巧，我们给这种技巧起个名字就叫作平滑（Smoothing）。



### 例题:

假设我们有一个新的水果，它的形状是圆形，口感是甜的，那么根据朴素贝叶斯，它属于苹果、甜橙和西瓜的概率分别是多少呢？

![图 25](https://incomparable9527.coding.net/p/imageBed/d/imageBed/git/raw/master/e7bb1d2b6d6271b843f6fe43a407494899f04695c881ed0971f8ad09b862abdb.png)  


apple 表示分类为苹果，shape-2 表示形状属性的值为 2（也就是圆形），taste-2 表示口感属性的值为 2。以此类推，我们还可计算该水果属于甜橙和西瓜的概率。


![图 26](https://incomparable9527.coding.net/p/imageBed/d/imageBed/git/raw/master/566411191bd8528f098fcae1cb13f0ff42a4b689de1e6f364b8dfbd38ebeb8f3.png)  


比较这三个数值，0.00198<0.00798<0.26934，所以计算机可以得出的结论，该水果属于甜橙的可能性是最大的


### 朴素贝叶斯分类主要包括这几个步骤

* `准备数据`：针对水果分类这个案例，我们收集了若干水果的实例，并从水果的常见属性入手，将其转化为计算机所能理解的数据。这种数据也被称为训练样本。
  
* `建立模型`：通过手头上水果的实例，我们让计算机统计每种水果、属性出现的先验概率，以及在某个水果分类下某种属性出现的条件概率。这个过程也被称为基于样本的训练。
  
* `分类新数据`：对于一颗新水果的属性数据，计算机根据已经建立的模型进行推导计算，得到该水果属于每个分类的概率，实现了分类的目的。这个过程也被称为预测。


### 朴素贝叶斯分类的优缺点

* 优点：

 1. 算法逻辑简单,易于实现

 2. 分类过程中时空开销小

* 缺点：

理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。



<!-- ### 例题: 

一对男女朋友，男生想女生求婚，男生的四个特点分别是不帅，性格不好，身高矮，不上进，请你判断一下女生是嫁还是不嫁？


转为数学问题就是比较p(嫁|(不帅、性格不好、身高矮、不上进))与p(不嫁|(不帅、性格不好、身高矮、不上进))的概率

#### 代入公式

![图 18](https://incomparable9527.coding.net/p/imageBed/d/imageBed/git/raw/master/8cc79df2582ccace9b21438ff3e8e6e25c80d045b34da026fbc8c08f7f240e89.png)  



通过朴素贝叶斯公式可以转化为好求的三个量,只要求得以下三个量,对比概率.就能拿到我们的结果.

* p(不帅、性格不好、身高矮、不上进|嫁)
* p（不帅、性格不好、身高矮、不上进)
* p(嫁)

#### 这三个量是如何求得?

```
p(不帅、性格不好、身高矮、不上进|嫁) = p(不帅|嫁)*p(性格不好|嫁)*p(身高矮|嫁)*p(不上进|嫁)
``` -->